{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polaris-lib in /opt/conda/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (4.66.2)\n",
      "Requirement already satisfied: loguru in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (0.7.2)\n",
      "Requirement already satisfied: typer in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (0.12.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (6.0.1)\n",
      "Requirement already satisfied: pydantic>=2 in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (2.7.4)\n",
      "Requirement already satisfied: pydantic-settings>=2 in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (2.3.3)\n",
      "Requirement already satisfied: authlib in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (1.3.1)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (0.27.0)\n",
      "Requirement already satisfied: tenacity in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (8.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (3.15.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (1.26.4)\n",
      "Requirement already satisfied: pandas<2.2.0 in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (2.1.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (1.5.0)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (0.13.2)\n",
      "Requirement already satisfied: datamol>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (0.12.5)\n",
      "Requirement already satisfied: zarr in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (2.18.2)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (16.1.0)\n",
      "Requirement already satisfied: fsspec[http] in /opt/conda/lib/python3.10/site-packages (from polaris-lib) (2024.6.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from datamol>=0.12.1->polaris-lib) (1.4.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from datamol>=0.12.1->polaris-lib) (3.9.0)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from datamol>=0.12.1->polaris-lib) (10.3.0)\n",
      "Requirement already satisfied: selfies in /opt/conda/lib/python3.10/site-packages (from datamol>=0.12.1->polaris-lib) (2.1.1)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from datamol>=0.12.1->polaris-lib) (4.2.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datamol>=0.12.1->polaris-lib) (24.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from datamol>=0.12.1->polaris-lib) (4.12.2)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from datamol>=0.12.1->polaris-lib) (6.4.0)\n",
      "Requirement already satisfied: rdkit in /opt/conda/lib/python3.10/site-packages (from datamol>=0.12.1->polaris-lib) (2023.9.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<2.2.0->polaris-lib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.2.0->polaris-lib) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.2.0->polaris-lib) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2->polaris-lib) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2->polaris-lib) (2.18.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings>=2->polaris-lib) (1.0.1)\n",
      "Requirement already satisfied: cryptography in /opt/conda/lib/python3.10/site-packages (from authlib->polaris-lib) (42.0.8)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]->polaris-lib) (3.9.5)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->polaris-lib) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->polaris-lib) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->polaris-lib) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->polaris-lib) (3.6)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->polaris-lib) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->polaris-lib) (0.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->polaris-lib) (3.5.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer->polaris-lib) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer->polaris-lib) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer->polaris-lib) (13.7.1)\n",
      "Requirement already satisfied: asciitree in /opt/conda/lib/python3.10/site-packages (from zarr->polaris-lib) (0.3.3)\n",
      "Requirement already satisfied: numcodecs>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from zarr->polaris-lib) (0.12.1)\n",
      "Requirement already satisfied: fasteners in /opt/conda/lib/python3.10/site-packages (from zarr->polaris-lib) (0.19)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]->polaris-lib) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]->polaris-lib) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]->polaris-lib) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]->polaris-lib) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]->polaris-lib) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]->polaris-lib) (4.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->datamol>=0.12.1->polaris-lib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->datamol>=0.12.1->polaris-lib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->datamol>=0.12.1->polaris-lib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->datamol>=0.12.1->polaris-lib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->datamol>=0.12.1->polaris-lib) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<2.2.0->polaris-lib) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer->polaris-lib) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer->polaris-lib) (2.18.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->polaris-lib) (1.2.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography->authlib->polaris-lib) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography->authlib->polaris-lib) (2.22)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->polaris-lib) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install polaris-lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-20 15:27:59.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris.hub.client\u001b[0m:\u001b[36mlogin\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mYou are already logged in to the Polaris Hub as  (andrea.roncoli.cs@gmail.com). Set `overwrite=True` to force re-authentication.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!polaris login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-20 19:24:56.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.0.0) is different from the currently installed version of Polaris (dev).\u001b[0m\n",
      "\u001b[32m2024-06-20 19:24:56.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.0.0) is different from the currently installed version of Polaris (dev).\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 0, 0, 0], dtype=uint8),\n",
       " {'CLASS_KIT_(T6701_mutant)': 0.0,\n",
       "  'CLASS_KIT_(V560G_mutant)': 0.0,\n",
       "  'CLASS_KIT': 0.0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polaris as po\n",
    "import datamol as dm\n",
    "import numpy as np\n",
    "\n",
    "benchmark = po.load_benchmark(\"polaris/pkis1-kit-wt-mut-c-1\")\n",
    "train, test = benchmark.get_train_test_split(featurization_fn=dm.to_fp)\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original SMILES: COc1cccc(COc2cc(sc2C(N)=O)-n2cnc3ccccc23)c1\n",
      "Canonical SMILES: COc1cccc(COc2cc(-n3cnc4ccccc43)sc2C(N)=O)c1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "def canonicalize_smiles(smiles: str) -> str:\n",
    "    try:\n",
    "        # Convert SMILES string to a molecule\n",
    "        molecule = Chem.MolFromSmiles(smiles)\n",
    "        if molecule:\n",
    "            # Generate canonical SMILES\n",
    "            canonical_smiles = Chem.MolToSmiles(molecule, canonical=True)\n",
    "            return canonical_smiles\n",
    "        else:\n",
    "            return \"Invalid SMILES string.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Example usage\n",
    "smiles = \"COc1cccc(COc2cc(sc2C(N)=O)-n2cnc3ccccc23)c1\"\n",
    "canonical_smiles = canonicalize_smiles(smiles)\n",
    "print(f\"Original SMILES: {smiles}\")\n",
    "print(f\"Canonical SMILES: {canonical_smiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "file_path = 'FULL CSV DATA.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "# Function to canonicalize SMILES\n",
    "def canonicalize_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:\n",
    "            return Chem.MolToSmiles(mol, canonical=True)\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Apply the canonicalization\n",
    "df['Canonical_SMILES'] = df['Compound ID'].apply(canonicalize_smiles)\n",
    "\n",
    "# Save the updated dataframe\n",
    "df.to_csv('canonicalized_smiles_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SMILES canonicalized: 355\n"
     ]
    }
   ],
   "source": [
    "# Compare original and canonicalized SMILES\n",
    "df['Changed'] = df['Compound ID'] != df['Canonical_SMILES']\n",
    "\n",
    "# Count the number of changed SMILES\n",
    "num_changed = df['Changed'].sum()\n",
    "\n",
    "# Save the updated dataframe with comparisons\n",
    "df.to_csv('canonicalized_smiles_comparison.csv', index=False)\n",
    "\n",
    "print(f\"Number of SMILES canonicalized: {num_changed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = train.y\n",
    "ys = np.stack([ys[target] for target in benchmark.target_cols], axis=1)\n",
    "ys.shape\n",
    "mask = ~np.any(np.isnan(ys), axis=1)\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(max_depth=5)\n",
    "model.fit(train.X[mask], ys[mask])\n",
    "y_pred = model.predict(test.X)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-2.1.0-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl (190.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.22.3 xgboost-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Stack probabilities and extract the required columns\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# We assume a binary classification for each target column (hence using index 1 for probabilities)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m xgb_y_prob \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(xgb_y_prob, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m xgb_y_prob \u001b[38;5;241m=\u001b[39m {k: xgb_y_prob[:, idx, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m idx, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(benchmark\u001b[38;5;241m.\u001b[39mtarget_cols)}\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(xgb_y_pred)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(xgb_y_prob)\n",
      "Cell \u001b[0;32mIn[22], line 22\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Stack probabilities and extract the required columns\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# We assume a binary classification for each target column (hence using index 1 for probabilities)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m xgb_y_prob \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(xgb_y_prob, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m xgb_y_prob \u001b[38;5;241m=\u001b[39m {k: \u001b[43mxgb_y_prob\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(benchmark\u001b[38;5;241m.\u001b[39mtarget_cols)}\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(xgb_y_pred)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(xgb_y_prob)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBClassifier(max_depth=5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb_model.fit(train.X[mask], ys[mask])\n",
    "\n",
    "# Predict on the test data\n",
    "xgb_y_pred = xgb_model.predict(test.X)\n",
    "\n",
    "# Predict probabilities on the test data\n",
    "xgb_y_prob = xgb_model.predict_proba(test.X)\n",
    "\n",
    "# Assuming benchmark.target_cols is a list of target column names\n",
    "# Ensure y_pred and y_prob have the expected structure\n",
    "xgb_y_pred = {k: (xgb_y_pred == idx).astype(int) for idx, k in enumerate(benchmark.target_cols)}\n",
    "\n",
    "# Stack probabilities and extract the required columns\n",
    "# We assume a binary classification for each target column (hence using index 1 for probabilities)\n",
    "xgb_y_prob = np.stack(xgb_y_prob, axis=1)\n",
    "xgb_y_prob = {k: xgb_y_prob[:, idx, 1] for idx, k in enumerate(benchmark.target_cols)}\n",
    "\n",
    "print(xgb_y_pred)\n",
    "print(xgb_y_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [15:50:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of y_pred: {'CLASS_KIT_(T6701_mutant)': (87,), 'CLASS_KIT_(V560G_mutant)': (87,), 'CLASS_KIT': (87,)}\n",
      "Shapes of y_prob: {'CLASS_KIT_(T6701_mutant)': (87,), 'CLASS_KIT_(V560G_mutant)': (87,), 'CLASS_KIT': (87,)}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Create a dictionary of XGBoost models, one for each target column\n",
    "models = {target: XGBClassifier(max_depth=5, use_label_encoder=False, eval_metric='logloss') for target in benchmark.target_cols}\n",
    "X = train.X\n",
    "\n",
    "# Fit each model on the corresponding target column\n",
    "for target, model in models.items():\n",
    "    y = train.y[target]\n",
    "    mask = ~np.isnan(y)  # Filter out rows where the target value is NaN\n",
    "    model.fit(X[mask], y[mask])\n",
    "\n",
    "# Predict probabilities and labels for each target column\n",
    "y_prob = {target: model.predict_proba(test.X)[:, 1] for target, model in models.items()}\n",
    "y_pred = {target: model.predict(test.X) for target, model in models.items()}\n",
    "\n",
    "# Evaluate results\n",
    "results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)\n",
    "\n",
    "# Print shapes of predictions and probabilities for debugging\n",
    "print(\"Shapes of y_pred:\", {target: pred.shape for target, pred in y_pred.items()})\n",
    "print(\"Shapes of y_prob:\", {target: prob.shape for target, prob in y_prob.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [20:59:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of y_pred: {'CLASS_KIT_(T6701_mutant)': (87,), 'CLASS_KIT_(V560G_mutant)': (87,), 'CLASS_KIT': (87,)}\n",
      "Shapes of y_prob: {'CLASS_KIT_(T6701_mutant)': (87,), 'CLASS_KIT_(V560G_mutant)': (87,), 'CLASS_KIT': (87,)}\n",
      "name=None description='' tags=[] user_attributes={} owner=None polaris_version='dev' results=   Test set              Target label              Metric     Score\n",
      "0      test  CLASS_KIT_(T6701_mutant)     Metric.accuracy  0.908046\n",
      "1      test  CLASS_KIT_(V560G_mutant)     Metric.accuracy  0.862069\n",
      "2      test                 CLASS_KIT     Metric.accuracy  0.678161\n",
      "3      test  CLASS_KIT_(T6701_mutant)           Metric.f1  0.600000\n",
      "4      test  CLASS_KIT_(V560G_mutant)           Metric.f1  0.142857\n",
      "5      test                 CLASS_KIT           Metric.f1  0.416667\n",
      "6      test  CLASS_KIT_(T6701_mutant)      Metric.roc_auc  0.724560\n",
      "7      test  CLASS_KIT_(V560G_mutant)      Metric.roc_auc  0.771111\n",
      "8      test                 CLASS_KIT      Metric.roc_auc  0.753648\n",
      "9      test  CLASS_KIT_(T6701_mutant)       Metric.pr_auc  0.663649\n",
      "10     test  CLASS_KIT_(V560G_mutant)       Metric.pr_auc  0.442056\n",
      "11     test                 CLASS_KIT       Metric.pr_auc  0.647750\n",
      "12     test  CLASS_KIT_(T6701_mutant)          Metric.mcc  0.621485\n",
      "13     test  CLASS_KIT_(V560G_mutant)          Metric.mcc  0.161063\n",
      "14     test                 CLASS_KIT          Metric.mcc  0.270312\n",
      "15     test  CLASS_KIT_(T6701_mutant)  Metric.cohen_kappa  0.557252\n",
      "16     test  CLASS_KIT_(V560G_mutant)  Metric.cohen_kappa  0.107692\n",
      "17     test                 CLASS_KIT  Metric.cohen_kappa  0.235405 benchmark_name='pkis1-kit-wt-mut-c-1' benchmark_owner=HubOwner(slug='polaris', external_id='org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu', type='organization') github_url=None paper_url=None contributors=None artifact_id=None benchmark_artifact_id='polaris/pkis1-kit-wt-mut-c-1'\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Create a dictionary of XGBoost models, one for each target column\n",
    "models = {target: XGBClassifier(max_depth=5, use_label_encoder=False, eval_metric='logloss') for target in benchmark.target_cols}\n",
    "X = train.X\n",
    "\n",
    "# Fit each model on the corresponding target column\n",
    "for target, model in models.items():\n",
    "    y = train.y[target]\n",
    "    mask = ~np.isnan(y)  # Filter out rows where the target value is NaN\n",
    "    model.fit(X[mask], y[mask])\n",
    "\n",
    "# Predict probabilities and labels for each target column\n",
    "y_prob = {target: model.predict_proba(test.X)[:, 1] for target, model in models.items()}\n",
    "y_pred = {target: model.predict(test.X) for target, model in models.items()}\n",
    "\n",
    "# Evaluate results\n",
    "results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)\n",
    "\n",
    "# Print shapes of predictions and probabilities for debugging\n",
    "print(\"Shapes of y_pred:\", {target: pred.shape for target, pred in y_pred.items()})\n",
    "print(\"Shapes of y_prob:\", {target: prob.shape for target, prob in y_prob.items()})\n",
    "\n",
    "\n",
    "results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [21:04:23] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of y_pred: {'CLASS_KIT_(T6701_mutant)': (87,), 'CLASS_KIT_(V560G_mutant)': (87,), 'CLASS_KIT': (87,)}\n",
      "Shapes of y_prob: {'CLASS_KIT_(T6701_mutant)': (87,), 'CLASS_KIT_(V560G_mutant)': (87,), 'CLASS_KIT': (87,)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-20 21:04:24.339\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mpolaris.hub.client\u001b[0m:\u001b[36mupload_results\u001b[0m:\u001b[36m492\u001b[0m - \u001b[32m\u001b[1mYour result has been successfully uploaded to the Hub. View it here: https://polarishub.io/benchmarks/polaris/pkis1-kit-wt-mut-c-1/0t1MtZlh5xFmdDx5wnfl6\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '0t1MtZlh5xFmdDx5wnfl6',\n",
       " 'createdAt': '2024-06-20T21:04:24.314Z',\n",
       " 'deletedAt': None,\n",
       " 'name': 'xgb-mae-binarylog-for-loop',\n",
       " 'slug': 'xgb-mae-binarylog-for-loop',\n",
       " 'description': 'xgb For Loop Based on Notebook',\n",
       " 'tags': [],\n",
       " 'userAttributes': {},\n",
       " 'access': 'private',\n",
       " 'isCertified': False,\n",
       " 'polarisVersion': 'dev',\n",
       " 'ownerId': 'n7RilKwWATJHjBVq7pcA9',\n",
       " 'creatorId': 'pXNk8yXN524Fm9fPLMrbe',\n",
       " 'benchmarkId': 'DZzlykxvBwlSA9uERL17A',\n",
       " 'results': [{'scores': {'f1': 0.4166666666666667,\n",
       "    'mcc': 0.2703121333894177,\n",
       "    'pr_auc': 0.6477497857237808,\n",
       "    'roc_auc': 0.7536475869809203,\n",
       "    'accuracy': 0.6781609195402298,\n",
       "    'cohen_kappa': 0.2354048964218456},\n",
       "   'testSet': 'test',\n",
       "   'targetLabel': 'CLASS_KIT'},\n",
       "  {'scores': {'f1': 0.6,\n",
       "    'mcc': 0.6214848238238696,\n",
       "    'pr_auc': 0.6636492977388023,\n",
       "    'roc_auc': 0.7245596868884541,\n",
       "    'accuracy': 0.9080459770114943,\n",
       "    'cohen_kappa': 0.5572519083969466},\n",
       "   'testSet': 'test',\n",
       "   'targetLabel': 'CLASS_KIT_(T6701_mutant)'},\n",
       "  {'scores': {'f1': 0.14285714285714285,\n",
       "    'mcc': 0.1610626476579478,\n",
       "    'pr_auc': 0.4420557437864857,\n",
       "    'roc_auc': 0.7711111111111111,\n",
       "    'accuracy': 0.8620689655172413,\n",
       "    'cohen_kappa': 0.10769230769230764},\n",
       "   'testSet': 'test',\n",
       "   'targetLabel': 'CLASS_KIT_(V560G_mutant)'}],\n",
       " 'githubUrl': None,\n",
       " 'paperUrl': None,\n",
       " 'owner': {'slug': 'team13',\n",
       "  'externalId': 'org_2i9KTJMUD0ZZzKDjNND8yEyQ9Pi',\n",
       "  'type': 'organization'},\n",
       " 'creator': {'slug': 'drernc',\n",
       "  'externalId': 'user_2i95KNh1umTCAxyhlvGZSWK0LUH',\n",
       "  'type': 'user'},\n",
       " 'contributors': [],\n",
       " 'benchmark': {'access': 'public',\n",
       "  'createdAt': '2023-12-08T20:44:08.863Z',\n",
       "  'description': 'A multitask classification benchmark for KIT wild type, T670I mutant and KV560G_mutant.',\n",
       "  'name': 'pkis1-kit-wt-mut-c-1',\n",
       "  'artifactId': 'polaris/pkis1-kit-wt-mut-c-1',\n",
       "  'owner': {'slug': 'polaris'}},\n",
       " 'review': None}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Create a dictionary of XGBoost models, one for each target column\n",
    "models = {target: XGBClassifier(max_depth=5, use_label_encoder=False, eval_metric='auc', objective='binary:logistic') for target in benchmark.target_cols}\n",
    "X = train.X\n",
    "\n",
    "# Fit each model on the corresponding target column\n",
    "for target, model in models.items():\n",
    "    y = train.y[target]\n",
    "    mask = ~np.isnan(y)  # Filter out rows where the target value is NaN\n",
    "    model.fit(X[mask], y[mask])\n",
    "\n",
    "# Predict probabilities and labels for each target column\n",
    "y_prob = {target: model.predict_proba(test.X)[:, 1] for target, model in models.items()}\n",
    "y_pred = {target: model.predict(test.X) for target, model in models.items()}\n",
    "\n",
    "# Evaluate results\n",
    "results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)\n",
    "\n",
    "# Print shapes of predictions and probabilities for debugging\n",
    "print(\"Shapes of y_pred:\", {target: pred.shape for target, pred in y_pred.items()})\n",
    "print(\"Shapes of y_prob:\", {target: prob.shape for target, prob in y_prob.items()})\n",
    "\n",
    "\n",
    "results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)\n",
    "results.name = \"xgb-auc-binarylog-for-loop\"\n",
    "results.description = \"xgb For Loop Based on Notebook\"\n",
    "results.upload_to_hub(owner=\"team13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import os\n",
    "import tqdm.auto as tqdm\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import make_scorer, log_loss, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def mkdirs(path : str):\n",
    "    \"\"\"Create a directory if it does not exist.\"\"\"\n",
    "\n",
    "    if not os.path.exists(path) : os.makedirs(path)\n",
    "\n",
    "def compute_fps(data):\n",
    "    \"\"\"Compute Morgan Fingerprints from SMILES.\"\"\"\n",
    "\n",
    "    fps = pd.DataFrame(np.array([AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smiles), 3, nBits=2048) for smiles in tqdm.tqdm(data.SMILES, desc='Computing Morgan Fingerprints from SMILES')]), index=data.index)\n",
    "\n",
    "    return fps\n",
    "\n",
    "def XGB_hyperparams():\n",
    "    \"\"\"Returns a dictionary of hyperparameters for XGBoost\"\"\"\n",
    "    return {\n",
    "        \"max_depth\": [4, 5, 6, 7, 8],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "        \"n_estimators\": [100, 200, 300, 400],\n",
    "        \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "        \"subsample\": [0.6, 0.8, 1.0],\n",
    "        \"gamma\": [0, 0.1, 0.2, 0.5],\n",
    "        \"reg_alpha\": [0, 0.01, 0.1, 1],\n",
    "        \"reg_lambda\": [1, 1.5, 2],\n",
    "    }\n",
    "\n",
    "def train_optim_XGB_STs(data_path, val_path, model_path, seed=2022, n_jobs=16, n_iter=50):\n",
    "    \"\"\"Trains XGBoost models for classification tasks using Randomized Search CV\"\"\"\n",
    "    mkdirs(model_path)\n",
    "\n",
    "    data = pd.read_csv(data_path)\n",
    "    data['split_index'] = -1\n",
    "\n",
    "    val = pd.read_csv(val_path)\n",
    "    val['split_index'] = 0\n",
    "\n",
    "    combined_data = pd.concat([data, val], axis=0, ignore_index=True)\n",
    "    targets = [col for col in combined_data.columns if col not in ['Canonical_SMILES', 'Compound ID' , 'Comp Conc. (µM)' , 'Chemotype','Pubmed ID', 'Split', 'Subset', 'set_index']]\n",
    "\n",
    "    fps = compute_fps(combined_data, radius=3, nbits=2048)\n",
    "\n",
    "    for target in tqdm.tqdm(targets, desc='Training XGB models'):\n",
    "        if os.path.exists(f'{model_path}/{target}.joblib'):\n",
    "            continue\n",
    "        \n",
    "        y = combined_data[target].dropna()\n",
    "        X = fps.iloc[y.index]\n",
    "        splits = PredefinedSplit(test_fold=combined_data.iloc[y.index].split_index)\n",
    "\n",
    "        model = XGBClassifier(random_state=seed, use_label_encoder=False, tree_method='gpu_hist')\n",
    "        rdnSearch = RandomizedSearchCV(\n",
    "            model, XGB_hyperparams(), n_iter=n_iter, cv=splits, n_jobs=1,\n",
    "            scoring=make_scorer(log_loss, needs_proba=True), random_state=seed\n",
    "        )\n",
    "        rdnSearch.fit(X, y)\n",
    "        joblib.dump(rdnSearch.best_estimator_, f'{model_path}/{target}.joblib')\n",
    "        print(f'Best parameters for {target}: {rdnSearch.best_params_}')\n",
    "        print(f'Best score for {target}: {rdnSearch.best_score_}')\n",
    "        print(f'Best model saved to {model_path}/{target}.joblib')\n",
    "\n",
    "def predict_XGB_STs(data_path, model_path, preds_path=None):\n",
    "    \"\"\"Predicts the targets for a dataset using trained XGBoost models\"\"\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    fps = compute_fps(data, radius=3, nbits=2048)\n",
    "    targets = [col for col in data.columns if col not in ['Canonical_SMILES', 'Compound ID' , 'Comp Conc. (µM)' , 'Chemotype','Pubmed ID', 'Split', 'Subset', 'set_index']]\n",
    "\n",
    "    preds = data.copy()\n",
    "\n",
    "    for target in tqdm.tqdm(targets, desc='Predicting with XGBoosts'):\n",
    "        model = joblib.load(f'{model_path}/{target}.joblib')\n",
    "        preds[target] = model.predict(fps)\n",
    "\n",
    "    if preds_path:\n",
    "        mkdirs(os.path.dirname(preds_path))\n",
    "        preds.to_csv(preds_path, index=False)\n",
    "\n",
    "    return preds\n",
    "\n",
    "def train_XGB_STs(data_path, model_path, seed=2022, gpu_id=0):\n",
    "    \"\"\"Trains XGBoost models for each target without hyperparameter tuning\"\"\"\n",
    "    mkdirs(model_path)\n",
    "\n",
    "    data = pd.read_csv(data_path)\n",
    "    targets = [col for col in data.columns if col != 'Canonical_SMILES']\n",
    "\n",
    "    fps = compute_fps(data, radius=3, nbits=2048)\n",
    "\n",
    "    for target in tqdm.tqdm(targets, desc='Training XGBoosts'):\n",
    "        y_train = data[target].dropna()\n",
    "        X_train = fps.iloc[y_train.index]\n",
    "        \n",
    "        model = XGBClassifier(tree_method='gpu_hist', random_state=seed, gpu_id=gpu_id)\n",
    "        model.fit(X_train, y_train)\n",
    "        joblib.dump(model, f'{model_path}/{target}.joblib')\n",
    "\n",
    "# Assuming benchmark is a provided module for evaluating the model\n",
    "def evaluate_models(models, test_X, test_y):\n",
    "    \"\"\"Evaluates models using benchmark\"\"\"\n",
    "    y_prob = {target: model.predict_proba(test_X)[:, 1] for target, model in models.items()}\n",
    "    y_pred = {target: model.predict(test_X) for target, model in models.items()}\n",
    "\n",
    "    results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)\n",
    "    print(\"Shapes of y_pred:\", {target: pred.shape for target, pred in y_pred.items()})\n",
    "    print(\"Shapes of y_prob:\", {target: prob.shape for target, prob in y_prob.items()})\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\"><tr><th>name</th><td>None</td></tr><tr><th>description</th><td></td></tr><tr><th>tags</th><td></td></tr><tr><th>user_attributes</th><td></td></tr><tr><th>owner</th><td>None</td></tr><tr><th>polaris_version</th><td>dev</td></tr><tr><th>benchmark_name</th><td>pkis1-kit-wt-mut-c-1</td></tr><tr><th>benchmark_owner</th><td><table border=\"1\"><tr><th>slug</th><td>polaris</td></tr><tr><th>external_id</th><td>org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu</td></tr><tr><th>type</th><td>organization</td></tr></table></td></tr><tr><th>github_url</th><td>None</td></tr><tr><th>paper_url</th><td>None</td></tr><tr><th>contributors</th><td>None</td></tr><tr><th>artifact_id</th><td>None</td></tr><tr><th>benchmark_artifact_id</th><td>polaris/pkis1-kit-wt-mut-c-1</td></tr><tr><th>results</th><td><table border=\"1\"><thead><tr><th>Test set</th><th>Target label</th><th>Metric</th><th>Score</th></tr></thead><tbody><tr><td>test</td><td>CLASS_KIT_(T6701_mutant)</td><td>accuracy</td><td>0.908045977</td></tr><tr><td>test</td><td>CLASS_KIT_(V560G_mutant)</td><td>accuracy</td><td>0.8620689655</td></tr><tr><td>test</td><td>CLASS_KIT</td><td>accuracy</td><td>0.6781609195</td></tr><tr><td>test</td><td>CLASS_KIT_(T6701_mutant)</td><td>f1</td><td>0.6</td></tr><tr><td>test</td><td>CLASS_KIT_(V560G_mutant)</td><td>f1</td><td>0.1428571429</td></tr><tr><td>test</td><td>CLASS_KIT</td><td>f1</td><td>0.4166666667</td></tr><tr><td>test</td><td>CLASS_KIT_(T6701_mutant)</td><td>roc_auc</td><td>0.7245596869</td></tr><tr><td>test</td><td>CLASS_KIT_(V560G_mutant)</td><td>roc_auc</td><td>0.7711111111</td></tr><tr><td>test</td><td>CLASS_KIT</td><td>roc_auc</td><td>0.753647587</td></tr><tr><td>test</td><td>CLASS_KIT_(T6701_mutant)</td><td>pr_auc</td><td>0.6636492977</td></tr><tr><td>test</td><td>CLASS_KIT_(V560G_mutant)</td><td>pr_auc</td><td>0.4420557438</td></tr><tr><td>test</td><td>CLASS_KIT</td><td>pr_auc</td><td>0.6477497857</td></tr><tr><td>test</td><td>CLASS_KIT_(T6701_mutant)</td><td>mcc</td><td>0.6214848238</td></tr><tr><td>test</td><td>CLASS_KIT_(V560G_mutant)</td><td>mcc</td><td>0.1610626477</td></tr><tr><td>test</td><td>CLASS_KIT</td><td>mcc</td><td>0.2703121334</td></tr><tr><td>test</td><td>CLASS_KIT_(T6701_mutant)</td><td>cohen_kappa</td><td>0.5572519084</td></tr><tr><td>test</td><td>CLASS_KIT_(V560G_mutant)</td><td>cohen_kappa</td><td>0.1076923077</td></tr><tr><td>test</td><td>CLASS_KIT</td><td>cohen_kappa</td><td>0.2354048964</td></tr></tbody></table></td></tr></table>"
      ],
      "text/plain": [
       "{\n",
       "  \"name\": null,\n",
       "  \"description\": \"\",\n",
       "  \"tags\": [],\n",
       "  \"user_attributes\": {},\n",
       "  \"owner\": null,\n",
       "  \"polaris_version\": \"dev\",\n",
       "  \"benchmark_name\": \"pkis1-kit-wt-mut-c-1\",\n",
       "  \"benchmark_owner\": {\n",
       "    \"slug\": \"polaris\",\n",
       "    \"external_id\": \"org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu\",\n",
       "    \"type\": \"organization\"\n",
       "  },\n",
       "  \"github_url\": null,\n",
       "  \"paper_url\": null,\n",
       "  \"contributors\": null,\n",
       "  \"artifact_id\": null,\n",
       "  \"benchmark_artifact_id\": \"polaris/pkis1-kit-wt-mut-c-1\",\n",
       "  \"results\": [\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(T6701_mutant)\",\n",
       "      \"Metric\": \"accuracy\",\n",
       "      \"Score\": 0.908045977\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(V560G_mutant)\",\n",
       "      \"Metric\": \"accuracy\",\n",
       "      \"Score\": 0.8620689655\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT\",\n",
       "      \"Metric\": \"accuracy\",\n",
       "      \"Score\": 0.6781609195\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(T6701_mutant)\",\n",
       "      \"Metric\": \"f1\",\n",
       "      \"Score\": 0.6\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(V560G_mutant)\",\n",
       "      \"Metric\": \"f1\",\n",
       "      \"Score\": 0.1428571429\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT\",\n",
       "      \"Metric\": \"f1\",\n",
       "      \"Score\": 0.4166666667\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(T6701_mutant)\",\n",
       "      \"Metric\": \"roc_auc\",\n",
       "      \"Score\": 0.7245596869\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(V560G_mutant)\",\n",
       "      \"Metric\": \"roc_auc\",\n",
       "      \"Score\": 0.7711111111\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT\",\n",
       "      \"Metric\": \"roc_auc\",\n",
       "      \"Score\": 0.753647587\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(T6701_mutant)\",\n",
       "      \"Metric\": \"pr_auc\",\n",
       "      \"Score\": 0.6636492977\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(V560G_mutant)\",\n",
       "      \"Metric\": \"pr_auc\",\n",
       "      \"Score\": 0.4420557438\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT\",\n",
       "      \"Metric\": \"pr_auc\",\n",
       "      \"Score\": 0.6477497857\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(T6701_mutant)\",\n",
       "      \"Metric\": \"mcc\",\n",
       "      \"Score\": 0.6214848238\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(V560G_mutant)\",\n",
       "      \"Metric\": \"mcc\",\n",
       "      \"Score\": 0.1610626477\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT\",\n",
       "      \"Metric\": \"mcc\",\n",
       "      \"Score\": 0.2703121334\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(T6701_mutant)\",\n",
       "      \"Metric\": \"cohen_kappa\",\n",
       "      \"Score\": 0.5572519084\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(V560G_mutant)\",\n",
       "      \"Metric\": \"cohen_kappa\",\n",
       "      \"Score\": 0.1076923077\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT\",\n",
       "      \"Metric\": \"cohen_kappa\",\n",
       "      \"Score\": 0.2354048964\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (276, 3) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m svm_model \u001b[38;5;241m=\u001b[39m SVC()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Fit the model on the training data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43msvm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Predict on the test data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m svm_y_pred \u001b[38;5;241m=\u001b[39m svm_model\u001b[38;5;241m.\u001b[39mpredict(test\u001b[38;5;241m.\u001b[39mX)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[1;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[1;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m    203\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1289\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1270\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1273\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1274\u001b[0m     X,\n\u001b[1;32m   1275\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1287\u001b[0m )\n\u001b[0;32m-> 1289\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1291\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1310\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m-> 1310\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n\u001b[1;32m   1312\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1377\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1367\u001b[0m             (\n\u001b[1;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1373\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1374\u001b[0m         )\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1377\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1379\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (276, 3) instead."
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 3, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = model.predict_proba(test.X)\n",
    "y_prob = np.stack(y_prob, axis=1)\n",
    "y_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m {k: y_pred[:, idx] \u001b[38;5;28;01mfor\u001b[39;00m idx, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(benchmark\u001b[38;5;241m.\u001b[39mtarget_cols)}\n\u001b[1;32m      2\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m {k: y_prob[:, idx, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m idx, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(benchmark\u001b[38;5;241m.\u001b[39mtarget_cols)}\n",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m {k: \u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(benchmark\u001b[38;5;241m.\u001b[39mtarget_cols)}\n\u001b[1;32m      2\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m {k: y_prob[:, idx, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m idx, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(benchmark\u001b[38;5;241m.\u001b[39mtarget_cols)}\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "y_pred = {k: y_pred[:, idx] for idx, k in enumerate(benchmark.target_cols)}\n",
    "y_prob = {k: y_prob[:, idx, 1] for idx, k in enumerate(benchmark.target_cols)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = {k: y_pred[:, idx] for idx, k in enumerate(benchmark.target_cols)}\n",
    "y_prob = {k: y_prob[:, idx, 1] for idx, k in enumerate(benchmark.target_cols)}\n",
    "results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m benchmark\u001b[38;5;241m.\u001b[39mevaluate(y_pred\u001b[38;5;241m=\u001b[39my_pred, y_prob\u001b[38;5;241m=\u001b[39my_prob)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/polaris/benchmark/_base.py:480\u001b[0m, in \u001b[0;36mBenchmarkSpecification.evaluate\u001b[0;34m(self, y_pred, y_prob)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m target_label, y_true_target \u001b[38;5;129;01min\u001b[39;00m y_true_subset\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    472\u001b[0m             \u001b[38;5;66;03m# Single-task metrics for a multi-task benchmark\u001b[39;00m\n\u001b[1;32m    473\u001b[0m             \u001b[38;5;66;03m# In such a setting, there can be NaN values, which we thus have to filter out.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m             mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(y_true_target)\n\u001b[1;32m    475\u001b[0m             score \u001b[38;5;241m=\u001b[39m metric(\n\u001b[1;32m    476\u001b[0m                 y_true\u001b[38;5;241m=\u001b[39my_true_target[mask],\n\u001b[1;32m    477\u001b[0m                 y_pred\u001b[38;5;241m=\u001b[39my_pred[test_label][target_label][mask]\n\u001b[1;32m    478\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m y_pred[test_label] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    479\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m--> 480\u001b[0m                 y_prob\u001b[38;5;241m=\u001b[39m\u001b[43my_prob\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_label\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_label\u001b[49m\u001b[43m]\u001b[49m[mask]\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m y_prob[test_label] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    483\u001b[0m             )\n\u001b[1;32m    484\u001b[0m             scores\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(scores)] \u001b[38;5;241m=\u001b[39m (test_label, target_label, metric, score)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BenchmarkResults(results\u001b[38;5;241m=\u001b[39mscores, benchmark_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, benchmark_owner\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner)\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-20 16:00:28.763\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mpolaris.hub.client\u001b[0m:\u001b[36mupload_results\u001b[0m:\u001b[36m492\u001b[0m - \u001b[32m\u001b[1mYour result has been successfully uploaded to the Hub. View it here: https://polarishub.io/benchmarks/polaris/pkis1-kit-wt-mut-c-1/SEKGzrlAcYw0k9mTdUPXL\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'SEKGzrlAcYw0k9mTdUPXL',\n",
       " 'createdAt': '2024-06-20T16:00:28.737Z',\n",
       " 'deletedAt': None,\n",
       " 'name': 'my-first-boost',\n",
       " 'slug': 'my-first-boost',\n",
       " 'description': 'Awal test ma3 el boost el 2adim',\n",
       " 'tags': [],\n",
       " 'userAttributes': {},\n",
       " 'access': 'private',\n",
       " 'isCertified': False,\n",
       " 'polarisVersion': 'dev',\n",
       " 'ownerId': 'n7RilKwWATJHjBVq7pcA9',\n",
       " 'creatorId': 'pXNk8yXN524Fm9fPLMrbe',\n",
       " 'benchmarkId': 'DZzlykxvBwlSA9uERL17A',\n",
       " 'results': [{'scores': {'f1': 0.4166666666666667,\n",
       "    'mcc': 0.2703121333894177,\n",
       "    'pr_auc': 0.6477497857237808,\n",
       "    'roc_auc': 0.7536475869809203,\n",
       "    'accuracy': 0.6781609195402298,\n",
       "    'cohen_kappa': 0.2354048964218456},\n",
       "   'testSet': 'test',\n",
       "   'targetLabel': 'CLASS_KIT'},\n",
       "  {'scores': {'f1': 0.6,\n",
       "    'mcc': 0.6214848238238696,\n",
       "    'pr_auc': 0.6636492977388023,\n",
       "    'roc_auc': 0.7245596868884541,\n",
       "    'accuracy': 0.9080459770114943,\n",
       "    'cohen_kappa': 0.5572519083969466},\n",
       "   'testSet': 'test',\n",
       "   'targetLabel': 'CLASS_KIT_(T6701_mutant)'},\n",
       "  {'scores': {'f1': 0.14285714285714285,\n",
       "    'mcc': 0.1610626476579478,\n",
       "    'pr_auc': 0.4420557437864857,\n",
       "    'roc_auc': 0.7711111111111111,\n",
       "    'accuracy': 0.8620689655172413,\n",
       "    'cohen_kappa': 0.10769230769230764},\n",
       "   'testSet': 'test',\n",
       "   'targetLabel': 'CLASS_KIT_(V560G_mutant)'}],\n",
       " 'githubUrl': None,\n",
       " 'paperUrl': None,\n",
       " 'owner': {'slug': 'team13',\n",
       "  'externalId': 'org_2i9KTJMUD0ZZzKDjNND8yEyQ9Pi',\n",
       "  'type': 'organization'},\n",
       " 'creator': {'slug': 'drernc',\n",
       "  'externalId': 'user_2i95KNh1umTCAxyhlvGZSWK0LUH',\n",
       "  'type': 'user'},\n",
       " 'contributors': [],\n",
       " 'benchmark': {'access': 'public',\n",
       "  'createdAt': '2023-12-08T20:44:08.863Z',\n",
       "  'description': 'A multitask classification benchmark for KIT wild type, T670I mutant and KV560G_mutant.',\n",
       "  'name': 'pkis1-kit-wt-mut-c-1',\n",
       "  'artifactId': 'polaris/pkis1-kit-wt-mut-c-1',\n",
       "  'owner': {'slug': 'polaris'}},\n",
       " 'review': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.name = \"my-first-boost\"\n",
    "results.description = \"Awal test ma3 el boost el 2adim\"\n",
    "results.upload_to_hub(owner=\"team13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-20 16:10:36.097\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mpolaris.hub.client\u001b[0m:\u001b[36mupload_results\u001b[0m:\u001b[36m492\u001b[0m - \u001b[32m\u001b[1mYour result has been successfully uploaded to the Hub. View it here: https://polarishub.io/benchmarks/polaris/pkis1-kit-wt-mut-c-1/AE8yDq0bFPm6zbvf5ry10\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'AE8yDq0bFPm6zbvf5ry10',\n",
       " 'createdAt': '2024-06-20T16:10:36.070Z',\n",
       " 'deletedAt': None,\n",
       " 'name': 'my-first-rf-for-loop',\n",
       " 'slug': 'my-first-rf-for-loop',\n",
       " 'description': 'RF For Loop Based on Notebook',\n",
       " 'tags': [],\n",
       " 'userAttributes': {},\n",
       " 'access': 'private',\n",
       " 'isCertified': False,\n",
       " 'polarisVersion': 'dev',\n",
       " 'ownerId': 'n7RilKwWATJHjBVq7pcA9',\n",
       " 'creatorId': 'pXNk8yXN524Fm9fPLMrbe',\n",
       " 'benchmarkId': 'DZzlykxvBwlSA9uERL17A',\n",
       " 'results': [{'scores': {'f1': 0,\n",
       "    'mcc': -0.08429675647647886,\n",
       "    'pr_auc': 0.7035527963473335,\n",
       "    'roc_auc': 0.82996632996633,\n",
       "    'accuracy': 0.6091954022988506,\n",
       "    'cohen_kappa': -0.022821576763485618},\n",
       "   'testSet': 'test',\n",
       "   'targetLabel': 'CLASS_KIT'},\n",
       "  {'scores': {'f1': 0,\n",
       "    'mcc': 0,\n",
       "    'pr_auc': 0.3508688285920429,\n",
       "    'roc_auc': 0.6908023483365949,\n",
       "    'accuracy': 0.8390804597701149,\n",
       "    'cohen_kappa': 0},\n",
       "   'testSet': 'test',\n",
       "   'targetLabel': 'CLASS_KIT_(T6701_mutant)'},\n",
       "  {'scores': {'f1': 0,\n",
       "    'mcc': 0,\n",
       "    'pr_auc': 0.6125134596849493,\n",
       "    'roc_auc': 0.8472222222222222,\n",
       "    'accuracy': 0.8620689655172413,\n",
       "    'cohen_kappa': 0},\n",
       "   'testSet': 'test',\n",
       "   'targetLabel': 'CLASS_KIT_(V560G_mutant)'}],\n",
       " 'githubUrl': None,\n",
       " 'paperUrl': None,\n",
       " 'owner': {'slug': 'team13',\n",
       "  'externalId': 'org_2i9KTJMUD0ZZzKDjNND8yEyQ9Pi',\n",
       "  'type': 'organization'},\n",
       " 'creator': {'slug': 'drernc',\n",
       "  'externalId': 'user_2i95KNh1umTCAxyhlvGZSWK0LUH',\n",
       "  'type': 'user'},\n",
       " 'contributors': [],\n",
       " 'benchmark': {'access': 'public',\n",
       "  'createdAt': '2023-12-08T20:44:08.863Z',\n",
       "  'description': 'A multitask classification benchmark for KIT wild type, T670I mutant and KV560G_mutant.',\n",
       "  'name': 'pkis1-kit-wt-mut-c-1',\n",
       "  'artifactId': 'polaris/pkis1-kit-wt-mut-c-1',\n",
       "  'owner': {'slug': 'polaris'}},\n",
       " 'review': None}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {target: RandomForestClassifier(max_depth=5) for target in benchmark.target_cols}\n",
    "X = train.X\n",
    "\n",
    "for target, model in models.items():\n",
    "  y = train.y[target]\n",
    "  mask = ~np.isnan(y)\n",
    "  model.fit(X[mask], y[mask])\n",
    "\n",
    "y_prob = {target: model.predict_proba(test.X)[:, 1] for target, model in models.items()}\n",
    "y_pred = {target: model.predict(test.X) for target, model in models.items()}\n",
    "\n",
    "results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)\n",
    "results.name = \"my-first-rf-for-loop\"\n",
    "results.description = \"RF For Loop Based on Notebook\"\n",
    "results.upload_to_hub(owner=\"team13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of y_pred: {'CLASS_KIT_(T6701_mutant)': (87,), 'CLASS_KIT_(V560G_mutant)': (87,), 'CLASS_KIT': (87,)}\n",
      "Shapes of y_prob: {'CLASS_KIT_(T6701_mutant)': (87,), 'CLASS_KIT_(V560G_mutant)': (87,), 'CLASS_KIT': (87,)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-20 16:13:18.731\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mpolaris.hub.client\u001b[0m:\u001b[36mupload_results\u001b[0m:\u001b[36m492\u001b[0m - \u001b[32m\u001b[1mYour result has been successfully uploaded to the Hub. View it here: https://polarishub.io/benchmarks/polaris/pkis1-kit-wt-mut-c-1/meBZUFUBPqMQ6EVAi1osd\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'meBZUFUBPqMQ6EVAi1osd',\n",
       " 'createdAt': '2024-06-20T16:13:18.704Z',\n",
       " 'deletedAt': None,\n",
       " 'name': 'my-first-SVM-for-loop',\n",
       " 'slug': 'my-first-svm-for-loop',\n",
       " 'description': 'SVM For Loop Based on Notebook',\n",
       " 'tags': [],\n",
       " 'userAttributes': {},\n",
       " 'access': 'private',\n",
       " 'isCertified': False,\n",
       " 'polarisVersion': 'dev',\n",
       " 'ownerId': 'n7RilKwWATJHjBVq7pcA9',\n",
       " 'creatorId': 'pXNk8yXN524Fm9fPLMrbe',\n",
       " 'benchmarkId': 'DZzlykxvBwlSA9uERL17A',\n",
       " 'results': [{'scores': {'f1': 0,\n",
       "    'mcc': 0,\n",
       "    'pr_auc': 0.7060944306375462,\n",
       "    'roc_auc': 0.781705948372615,\n",
       "    'accuracy': 0.6206896551724138,\n",
       "    'cohen_kappa': 0},\n",
       "   'testSet': 'test',\n",
       "   'targetLabel': 'CLASS_KIT'},\n",
       "  {'scores': {'f1': 0,\n",
       "    'mcc': 0,\n",
       "    'pr_auc': 0.6336943478637297,\n",
       "    'roc_auc': 0.7279843444227005,\n",
       "    'accuracy': 0.8390804597701149,\n",
       "    'cohen_kappa': 0},\n",
       "   'testSet': 'test',\n",
       "   'targetLabel': 'CLASS_KIT_(T6701_mutant)'},\n",
       "  {'scores': {'f1': 0,\n",
       "    'mcc': 0,\n",
       "    'pr_auc': 0.40770997612871224,\n",
       "    'roc_auc': 0.6822222222222222,\n",
       "    'accuracy': 0.8620689655172413,\n",
       "    'cohen_kappa': 0},\n",
       "   'testSet': 'test',\n",
       "   'targetLabel': 'CLASS_KIT_(V560G_mutant)'}],\n",
       " 'githubUrl': None,\n",
       " 'paperUrl': None,\n",
       " 'owner': {'slug': 'team13',\n",
       "  'externalId': 'org_2i9KTJMUD0ZZzKDjNND8yEyQ9Pi',\n",
       "  'type': 'organization'},\n",
       " 'creator': {'slug': 'drernc',\n",
       "  'externalId': 'user_2i95KNh1umTCAxyhlvGZSWK0LUH',\n",
       "  'type': 'user'},\n",
       " 'contributors': [],\n",
       " 'benchmark': {'access': 'public',\n",
       "  'createdAt': '2023-12-08T20:44:08.863Z',\n",
       "  'description': 'A multitask classification benchmark for KIT wild type, T670I mutant and KV560G_mutant.',\n",
       "  'name': 'pkis1-kit-wt-mut-c-1',\n",
       "  'artifactId': 'polaris/pkis1-kit-wt-mut-c-1',\n",
       "  'owner': {'slug': 'polaris'}},\n",
       " 'review': None}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create a dictionary of SVM models, one for each target column\n",
    "models = {target: SVC(probability=True) for target in benchmark.target_cols}\n",
    "X = train.X\n",
    "\n",
    "# Fit each model on the corresponding target column\n",
    "for target, model in models.items():\n",
    "    y = train.y[target]\n",
    "    mask = ~np.isnan(y)  # Filter out rows where the target value is NaN\n",
    "    model.fit(X[mask], y[mask])\n",
    "\n",
    "# Predict probabilities and labels for each target column\n",
    "y_prob = {target: model.predict_proba(test.X)[:, 1] for target, model in models.items()}\n",
    "y_pred = {target: model.predict(test.X) for target, model in models.items()}\n",
    "\n",
    "# Evaluate results\n",
    "results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)\n",
    "\n",
    "# Print shapes of predictions and probabilities for debugging\n",
    "print(\"Shapes of y_pred:\", {target: pred.shape for target, pred in y_pred.items()})\n",
    "print(\"Shapes of y_prob:\", {target: prob.shape for target, prob in y_prob.items()})\n",
    "results.name = \"my-first-SVM-for-loop\"\n",
    "results.description = \"SVM For Loop Based on Notebook\"\n",
    "results.upload_to_hub(owner=\"team13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 277 features, but SVC is expecting 276 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m K_test \u001b[38;5;241m=\u001b[39m tanimoto_kernel(test\u001b[38;5;241m.\u001b[39mX, X)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Predict probabilities and labels for each target column\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m {target: model\u001b[38;5;241m.\u001b[39mpredict_proba(K_test)[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m target, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     36\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m {target: model\u001b[38;5;241m.\u001b[39mpredict(K_test) \u001b[38;5;28;01mfor\u001b[39;00m target, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Evaluate results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 35\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m K_test \u001b[38;5;241m=\u001b[39m tanimoto_kernel(test\u001b[38;5;241m.\u001b[39mX, X)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Predict probabilities and labels for each target column\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m {target: \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK_test\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m target, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     36\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m {target: model\u001b[38;5;241m.\u001b[39mpredict(K_test) \u001b[38;5;28;01mfor\u001b[39;00m target, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Evaluate results\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:856\u001b[0m, in \u001b[0;36mBaseSVC.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;129m@available_if\u001b[39m(_check_proba)\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    831\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \n\u001b[1;32m    833\u001b[0m \u001b[38;5;124;03m    The model needs to have probability information computed at training\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;124;03m    datasets.\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobA_\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobB_\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\n\u001b[1;32m    859\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba is not available when fitted with probability=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:606\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    603\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 606\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m    616\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 277 features, but SVC is expecting 276 features as input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "def tanimoto_kernel(X, Y=None):\n",
    "    \"\"\"\n",
    "    Compute the Tanimoto kernel between two matrices X and Y.\n",
    "    \"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    similarity = np.dot(X, Y.T)\n",
    "    sum_x = np.sum(X, axis=1)\n",
    "    sum_y = np.sum(Y, axis=1)\n",
    "    denominator = sum_x[:, np.newaxis] + sum_y - similarity\n",
    "    kernel = similarity / denominator\n",
    "    return kernel\n",
    "\n",
    "# Create a dictionary of SVM models, one for each target column with custom Tanimoto kernel\n",
    "models = {target: SVC(kernel='precomputed', probability=True) for target in benchmark.target_cols}\n",
    "X = train.X\n",
    "\n",
    "# Compute the kernel matrix for the training data\n",
    "K_train = tanimoto_kernel(X)\n",
    "\n",
    "# Fit each model on the corresponding target column\n",
    "for target, model in models.items():\n",
    "    y = train.y[target]\n",
    "    mask = ~np.isnan(y)  # Filter out rows where the target value is NaN\n",
    "    model.fit(K_train[mask][:, mask], y[mask])\n",
    "\n",
    "# Compute the kernel matrix for the test data\n",
    "K_test = tanimoto_kernel(test.X, X)\n",
    "\n",
    "# Predict probabilities and labels for each target column\n",
    "y_prob = {target: model.predict_proba(K_test)[:, 1] for target, model in models.items()}\n",
    "y_pred = {target: model.predict(K_test) for target, model in models.items()}\n",
    "\n",
    "# Evaluate results\n",
    "results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)\n",
    "\n",
    "# Print shapes of predictions and probabilities for debugging\n",
    "print(\"Shapes of y_pred:\", {target: pred.shape for target, pred in y_pred.items()})\n",
    "print(\"Shapes of y_prob:\", {target: prob.shape for target, prob in y_prob.items()})\n",
    "results.name = \"my-first-SVM-tanimoto-kernel\"\n",
    "results.description = \"SVM Tanimoto Kernel Based on Notebook\"\n",
    "results.upload_to_hub(owner=\"team13\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 277 features, but SVC is expecting 276 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m K_test \u001b[38;5;241m=\u001b[39m tanimoto_kernel(test\u001b[38;5;241m.\u001b[39mX, X)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Predict probabilities and labels for each target column\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m {target: model\u001b[38;5;241m.\u001b[39mpredict_proba(K_test)[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m target, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     36\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m {target: model\u001b[38;5;241m.\u001b[39mpredict(K_test) \u001b[38;5;28;01mfor\u001b[39;00m target, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Evaluate results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m K_test \u001b[38;5;241m=\u001b[39m tanimoto_kernel(test\u001b[38;5;241m.\u001b[39mX, X)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Predict probabilities and labels for each target column\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m {target: \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK_test\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m target, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     36\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m {target: model\u001b[38;5;241m.\u001b[39mpredict(K_test) \u001b[38;5;28;01mfor\u001b[39;00m target, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Evaluate results\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:856\u001b[0m, in \u001b[0;36mBaseSVC.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;129m@available_if\u001b[39m(_check_proba)\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    831\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \n\u001b[1;32m    833\u001b[0m \u001b[38;5;124;03m    The model needs to have probability information computed at training\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;124;03m    datasets.\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobA_\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobB_\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\n\u001b[1;32m    859\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba is not available when fitted with probability=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:606\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    603\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 606\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m    616\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 277 features, but SVC is expecting 276 features as input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "def tanimoto_kernel(X, Y=None):\n",
    "    \"\"\"\n",
    "    Compute the Tanimoto kernel between two matrices X and Y.\n",
    "    \"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    similarity = np.dot(X, Y.T)\n",
    "    sum_x = np.sum(X, axis=1)\n",
    "    sum_y = np.sum(Y, axis=1)\n",
    "    denominator = sum_x[:, np.newaxis] + sum_y - similarity\n",
    "    kernel = similarity / denominator\n",
    "    return kernel\n",
    "\n",
    "# Create a dictionary of SVM models, one for each target column with custom Tanimoto kernel\n",
    "models = {target: SVC(kernel='precomputed', probability=True) for target in benchmark.target_cols}\n",
    "X = train.X\n",
    "\n",
    "# Compute the kernel matrix for the training data\n",
    "K_train = tanimoto_kernel(X)\n",
    "\n",
    "# Fit each model on the corresponding target column\n",
    "for target, model in models.items():\n",
    "    y = train.y[target]\n",
    "    mask = ~np.isnan(y)  # Filter out rows where the target value is NaN\n",
    "    model.fit(K_train[mask][:, mask], y[mask])\n",
    "\n",
    "# Compute the kernel matrix for the test data\n",
    "K_test = tanimoto_kernel(test.X, X)\n",
    "\n",
    "# Predict probabilities and labels for each target column\n",
    "y_prob = {target: model.predict_proba(K_test)[:, 1] for target, model in models.items()}\n",
    "y_pred = {target: model.predict(K_test) for target, model in models.items()}\n",
    "\n",
    "# Evaluate results\n",
    "results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)\n",
    "\n",
    "# Print shapes of predictions and probabilities for debugging\n",
    "print(\"Shapes of y_pred:\", {target: pred.shape for target, pred in y_pred.items()})\n",
    "print(\"Shapes of y_prob:\", {target: prob.shape for target, prob in y_prob.items()})\n",
    "results.name = \"my-first-SVM-tanimoto-kernel\"\n",
    "results.description = \"SVM Tanimoto Kernel Based on Notebook\"\n",
    "results.upload_to_hub(owner=\"team13\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (87,277) and (2048,277) not aligned: 277 (dim 1) != 2048 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Make predictions for each model\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 58\u001b[0m     y_prob[target] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     59\u001b[0m     y_pred[target] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test\u001b[38;5;241m.\u001b[39mX)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Evaluate results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 35\u001b[0m, in \u001b[0;36mTanimotoSVC.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     34\u001b[0m     K_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_kernel(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_X_fit)\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:864\u001b[0m, in \u001b[0;36mBaseSVC.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba is not available when fitted with probability=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n\u001b[1;32m    861\u001b[0m pred_proba \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict_proba \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict_proba\n\u001b[1;32m    863\u001b[0m )\n\u001b[0;32m--> 864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpred_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:897\u001b[0m, in \u001b[0;36mBaseSVC._dense_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dense_predict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m--> 897\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(kernel):\n",
      "Cell \u001b[0;32mIn[12], line 40\u001b[0m, in \u001b[0;36mTanimotoSVC._compute_kernel\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_X_fit\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtanimoto_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m, in \u001b[0;36mtanimoto_kernel\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtanimoto_kernel\u001b[39m(X, Y):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Compute the Tanimoto kernel between two matrices X and Y.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     sum_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m     sum_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(Y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (87,277) and (2048,277) not aligned: 277 (dim 1) != 2048 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "def tanimoto_kernel(X, Y):\n",
    "    \"\"\"\n",
    "    Compute the Tanimoto kernel between two matrices X and Y.\n",
    "    \"\"\"\n",
    "    similarity = np.dot(X, Y.T)\n",
    "    sum_x = np.sum(X, axis=1)\n",
    "    sum_y = np.sum(Y, axis=1)\n",
    "    denominator = sum_x[:, np.newaxis] + sum_y - similarity\n",
    "    kernel = similarity / denominator\n",
    "    return kernel\n",
    "\n",
    "class TanimotoSVC(SVC):\n",
    "    \"\"\"\n",
    "    SVC with a Tanimoto kernel.\n",
    "    \"\"\"\n",
    "    def __init__(self, probability=True, **kwargs):\n",
    "        super().__init__(kernel='precomputed', probability=probability, **kwargs)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self._X_fit = X  # Save training data for use in kernel computation\n",
    "        K_train = self._compute_kernel(X)\n",
    "        super().fit(K_train, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        K_test = self._compute_kernel(X, self._X_fit)\n",
    "        return super().predict(K_test)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        K_test = self._compute_kernel(X, self._X_fit)\n",
    "        return super().predict_proba(K_test)\n",
    "    \n",
    "    def _compute_kernel(self, X, Y=None):\n",
    "        if Y is None:\n",
    "            Y = self._X_fit\n",
    "        return tanimoto_kernel(X, Y)\n",
    "\n",
    "# Create a dictionary of SVM models, one for each target column\n",
    "models = {target: TanimotoSVC() for target in benchmark.target_cols}\n",
    "X = train.X\n",
    "\n",
    "# Fit each model on the corresponding target column\n",
    "for target, model in models.items():\n",
    "    y = train.y[target]\n",
    "    mask = ~np.isnan(y)  # Filter out rows where the target value is NaN\n",
    "    model.fit(X[mask], y[mask])\n",
    "\n",
    "# Predict probabilities and labels for each target column\n",
    "y_prob = {}\n",
    "y_pred = {}\n",
    "\n",
    "# Make predictions for each model\n",
    "for target, model in models.items():\n",
    "    y_prob[target] = model.predict_proba(test.X)[:, 1]\n",
    "    y_pred[target] = model.predict(test.X)\n",
    "\n",
    "# Evaluate results\n",
    "results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)\n",
    "\n",
    "# Print shapes of predictions and probabilities for debugging\n",
    "print(\"Shapes of y_pred:\", {target: pred.shape for target, pred in y_pred.items()})\n",
    "print(\"Shapes of y_prob:\", {target: prob.shape for target, prob in y_prob.items()})\n",
    "results.name = \"my-first-SVM-tanimoto-kernel-trick\"\n",
    "results.description = \"SVM Tanimoto Kernel with Kernel Trick\"\n",
    "results.upload_to_hub(owner=\"team13\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (87,277) and (2048,277) not aligned: 277 (dim 1) != 2048 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 66\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Make predictions for each model\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 66\u001b[0m     y_prob[target] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     67\u001b[0m     y_pred[target] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test\u001b[38;5;241m.\u001b[39mX)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Evaluate results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 37\u001b[0m, in \u001b[0;36mTanimotoSVC.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     36\u001b[0m     K_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_kernel(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_X_fit)\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:864\u001b[0m, in \u001b[0;36mBaseSVC.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba is not available when fitted with probability=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n\u001b[1;32m    861\u001b[0m pred_proba \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict_proba \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict_proba\n\u001b[1;32m    863\u001b[0m )\n\u001b[0;32m--> 864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpred_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:897\u001b[0m, in \u001b[0;36mBaseSVC._dense_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dense_predict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m--> 897\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(kernel):\n",
      "Cell \u001b[0;32mIn[13], line 42\u001b[0m, in \u001b[0;36mTanimotoSVC._compute_kernel\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_X_fit\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtanimoto_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m, in \u001b[0;36mtanimoto_kernel\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     Y \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m---> 11\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m sum_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m sum_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(Y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (87,277) and (2048,277) not aligned: 277 (dim 1) != 2048 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def tanimoto_kernel(X, Y=None):\n",
    "    \"\"\"\n",
    "    Compute the Tanimoto kernel between two matrices X and Y.\n",
    "    If Y is None, compute the kernel between X and itself.\n",
    "    \"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    similarity = np.dot(X, Y.T)\n",
    "    sum_x = np.sum(X, axis=1)\n",
    "    sum_y = np.sum(Y, axis=1)\n",
    "    denominator = sum_x[:, np.newaxis] + sum_y - similarity\n",
    "    kernel = similarity / denominator\n",
    "    return kernel\n",
    "\n",
    "class TanimotoSVC(SVC):\n",
    "    \"\"\"\n",
    "    SVC with a Tanimoto kernel.\n",
    "    \"\"\"\n",
    "    def __init__(self, probability=True, **kwargs):\n",
    "        super().__init__(kernel='precomputed', probability=probability, **kwargs)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self._X_fit = X  # Save training data for use in kernel computation\n",
    "        K_train = self._compute_kernel(X)\n",
    "        super().fit(K_train, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        K_test = self._compute_kernel(X, self._X_fit)\n",
    "        return super().predict(K_test)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        K_test = self._compute_kernel(X, self._X_fit)\n",
    "        return super().predict_proba(K_test)\n",
    "    \n",
    "    def _compute_kernel(self, X, Y=None):\n",
    "        if Y is None:\n",
    "            Y = self._X_fit\n",
    "        return tanimoto_kernel(X, Y)\n",
    "\n",
    "# Create a dictionary of SVM models, one for each target column\n",
    "models = {target: TanimotoSVC() for target in benchmark.target_cols}\n",
    "X = train.X\n",
    "\n",
    "# Compute the Tanimoto kernel matrix for the training data\n",
    "K_train = tanimoto_kernel(X)\n",
    "\n",
    "# Fit each model on the corresponding target column\n",
    "for target, model in models.items():\n",
    "    y = train.y[target]\n",
    "    mask = ~np.isnan(y)  # Filter out rows where the target value is NaN\n",
    "    model.fit(X[mask], y[mask])  # X[mask] is passed for consistency, the class handles the kernel\n",
    "\n",
    "# Compute the Tanimoto kernel matrix for the test data relative to the training data\n",
    "K_test = tanimoto_kernel(test.X, X)\n",
    "\n",
    "# Predict probabilities and labels for each target column\n",
    "y_prob = {}\n",
    "y_pred = {}\n",
    "\n",
    "# Make predictions for each model\n",
    "for target, model in models.items():\n",
    "    y_prob[target] = model.predict_proba(test.X)[:, 1]\n",
    "    y_pred[target] = model.predict(test.X)\n",
    "\n",
    "# Evaluate results\n",
    "results = benchmark.evaluate(y_pred=y_pred, y_prob=y_prob)\n",
    "\n",
    "# Print shapes of predictions and probabilities for debugging\n",
    "print(\"Shapes of y_pred:\", {target: pred.shape for target, pred in y_pred.items()})\n",
    "print(\"Shapes of y_prob:\", {target: prob.shape for target, prob in y_prob.items()})\n",
    "results.name = \"my-first-SVM-tanimoto-kernel-compute\"\n",
    "results.description = \"SVM Tanimoto Kernel Computation for Each Sample\"\n",
    "results.upload_to_hub(owner=\"team13\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
